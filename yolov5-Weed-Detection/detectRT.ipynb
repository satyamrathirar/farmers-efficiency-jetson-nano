{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d373dff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TensorRT engine...\n",
      "Number of bindings: 2\n",
      "Binding 0: name=images, is_input=True, shape=(1, 3, 640, 640), dtype=DataType.FLOAT\n",
      "Binding 1: name=output0, is_input=False, shape=(1, 25200, 13), dtype=DataType.FLOAT\n",
      "TensorRT engine loaded successfully\n",
      "Available images: ['6', '7', '4', '8', '5', '1', '2', '3']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1323e28bae1547fb8a82fa565ead2d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Image:', options=('6', '7', '4', '8', '5', '1', '2', '3'), value='6'), Buâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e195b03ab07a421bb14a21147a91426a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import os\n",
    "\n",
    "# Class labels\n",
    "class_names = ['herb paris', 'karela', 'small weed', 'grass', 'tori', 'horseweed', 'Bhindi', 'weed']\n",
    "\n",
    "class TRTInference:\n",
    "    def __init__(self, engine_path):\n",
    "        # Load TRT engine\n",
    "        self.logger = trt.Logger(trt.Logger.WARNING)\n",
    "        with open(engine_path, \"rb\") as f, trt.Runtime(self.logger) as runtime:\n",
    "            self.engine = runtime.deserialize_cuda_engine(f.read())\n",
    "        \n",
    "        self.context = self.engine.create_execution_context()\n",
    "        \n",
    "        # Print engine information\n",
    "        print(f\"Number of bindings: {self.engine.num_bindings}\")\n",
    "        \n",
    "        # Allocate memory for input/output bindings\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.allocations = []\n",
    "        \n",
    "        for i in range(self.engine.num_bindings):\n",
    "            is_input = self.engine.binding_is_input(i)\n",
    "            name = self.engine.get_binding_name(i)\n",
    "            dtype = self.engine.get_binding_dtype(i)\n",
    "            shape = self.engine.get_binding_shape(i)\n",
    "            \n",
    "            # Print binding information\n",
    "            print(f\"Binding {i}: name={name}, is_input={is_input}, shape={shape}, dtype={dtype}\")\n",
    "            \n",
    "            # Get the size in bytes for the data type\n",
    "            if dtype == trt.DataType.FLOAT:\n",
    "                dtype_size = 4  # 4 bytes for float32\n",
    "            elif dtype == trt.DataType.HALF:\n",
    "                dtype_size = 2  # 2 bytes for float16\n",
    "            elif dtype == trt.DataType.INT8:\n",
    "                dtype_size = 1  # 1 byte for int8\n",
    "            else:\n",
    "                dtype_size = 4  # Default to 4 bytes\n",
    "                \n",
    "            # Calculate total size\n",
    "            size = trt.volume(shape) * dtype_size\n",
    "            \n",
    "            # Allocate CUDA memory\n",
    "            allocation = cuda.mem_alloc(size)\n",
    "            \n",
    "            if is_input:\n",
    "                self.inputs.append({\"index\": i, \"name\": name, \"dtype\": dtype, \"shape\": shape, \"allocation\": allocation})\n",
    "            else:\n",
    "                self.outputs.append({\"index\": i, \"name\": name, \"dtype\": dtype, \"shape\": shape, \"allocation\": allocation})\n",
    "            \n",
    "            self.allocations.append(allocation)\n",
    "    \n",
    "    def infer(self, img_input):\n",
    "        try:\n",
    "            # Copy input data to GPU\n",
    "            cuda.memcpy_htod(self.inputs[0][\"allocation\"], img_input.astype(np.float32).ravel())\n",
    "            \n",
    "            # Run inference\n",
    "            try:\n",
    "                # Try the newer API first\n",
    "                self.context.execute_v2(self.allocations)\n",
    "            except AttributeError:\n",
    "                # Fall back to older API if execute_v2 is not available\n",
    "                print(\"Falling back to execute_async...\")\n",
    "                self.context.execute_async(batch_size=1, bindings=self.allocations, stream_handle=cuda.Stream().handle)\n",
    "            \n",
    "            # Copy output back to CPU\n",
    "            output_shape = self.outputs[0][\"shape\"]\n",
    "            output = np.zeros(output_shape, dtype=np.float32)\n",
    "            cuda.memcpy_dtoh(output, self.outputs[0][\"allocation\"])\n",
    "            \n",
    "            return [output]\n",
    "        except Exception as e:\n",
    "            print(f\"Error during inference: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Return an empty array with the expected shape\n",
    "            return [np.zeros(self.outputs[0][\"shape\"], dtype=np.float32)]\n",
    "\n",
    "# Preprocess image\n",
    "def preprocess(img_path, img_size=640):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Image not found at {img_path}\")\n",
    "        return None\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.transpose(img, (2, 0, 1))  # HWC to CHW\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Postprocess with NMS\n",
    "def postprocess(predictions, conf_thres=0.25, iou_thres=0.45):\n",
    "    try:\n",
    "        preds = np.squeeze(predictions[0])  # shape: (N, 85)\n",
    "        \n",
    "        # Print shape for debugging\n",
    "        print(f\"Output shape: {preds.shape}\")\n",
    "        \n",
    "        # Handle different output formats (some TensorRT engines may have different shapes)\n",
    "        if len(preds.shape) == 1:\n",
    "            # If output is flattened, reshape it based on YOLOv5 output format\n",
    "            num_classes = len(class_names)\n",
    "            num_boxes = preds.shape[0] // (5 + num_classes)\n",
    "            preds = preds.reshape(num_boxes, 5 + num_classes)\n",
    "            print(f\"Reshaped to: {preds.shape}\")\n",
    "        \n",
    "        # Ensure we have the correct number of columns\n",
    "        if preds.shape[1] < 5 + len(class_names):\n",
    "            print(f\"Warning: Output shape {preds.shape} doesn't match expected format\")\n",
    "            return []\n",
    "        \n",
    "        boxes = preds[:, :4]\n",
    "        objectness = preds[:, 4]\n",
    "        class_probs = preds[:, 5:5+len(class_names)]  # Only take as many classes as we have names for\n",
    "        class_ids = np.argmax(class_probs, axis=1)\n",
    "        class_scores = class_probs[np.arange(len(class_ids)), class_ids]\n",
    "        scores = objectness * class_scores\n",
    "        \n",
    "        results = []\n",
    "        for box, score, cls in zip(boxes, scores, class_ids):\n",
    "            if score > conf_thres:\n",
    "                cx, cy, w, h = box\n",
    "                x = int(cx - w / 2)\n",
    "                y = int(cy - h / 2)\n",
    "                results.append(([x, y, int(w), int(h)], float(score), int(cls)))\n",
    "        \n",
    "        # Apply NMS\n",
    "        if not results:\n",
    "            return []\n",
    "        \n",
    "        boxes_xywh = [r[0] for r in results]\n",
    "        scores = [r[1] for r in results]\n",
    "        indices = cv2.dnn.NMSBoxes(boxes_xywh, scores, score_threshold=conf_thres, nms_threshold=iou_thres)\n",
    "        \n",
    "        # Handle different return formats of NMSBoxes (OpenCV version differences)\n",
    "        if len(indices) > 0 and isinstance(indices[0], (list, tuple, np.ndarray)):\n",
    "            indices = [i[0] for i in indices]\n",
    "        \n",
    "        return [results[i] for i in indices]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in postprocessing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "def process_image(trt_model, img_num):\n",
    "    try:\n",
    "        img_path = f\"images/{img_num}.jpg\"\n",
    "        print(f\"Processing image: {img_path}\")\n",
    "        \n",
    "        # Preprocess image\n",
    "        img_input = preprocess(img_path)\n",
    "        if img_input is None:\n",
    "            return None\n",
    "        \n",
    "        # Measure inference time\n",
    "        start_time = time.time()\n",
    "        predictions = trt_model.infer(img_input)\n",
    "        inference_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "        print(f\"TensorRT Inference Time: {inference_time:.2f} ms\")\n",
    "        \n",
    "        # Process results\n",
    "        results = postprocess(predictions)\n",
    "        print(f\"Found {len(results)} detections\")\n",
    "        \n",
    "        # Draw results\n",
    "        original = cv2.imread(img_path)\n",
    "        original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)  # Convert to RGB for matplotlib\n",
    "        original_resized = cv2.resize(original_rgb, (640, 640))\n",
    "        \n",
    "        # Create a copy for drawing\n",
    "        img_with_boxes = original_resized.copy()\n",
    "        \n",
    "        for (x, y, w, h), score, cls in results:\n",
    "            cv2.rectangle(img_with_boxes, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            label = f\"{class_names[cls]}: {score:.2f}\"\n",
    "            cv2.putText(img_with_boxes, label, (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "        \n",
    "        # Save result\n",
    "        output_filename = f\"output/trt_output_{img_num}.jpg\"\n",
    "        cv2.imwrite(output_filename, cv2.cvtColor(img_with_boxes, cv2.COLOR_RGB2BGR))\n",
    "        print(f\"Results saved to {output_filename}\")\n",
    "        \n",
    "        return {\n",
    "            'original': original_resized,\n",
    "            'with_boxes': img_with_boxes,\n",
    "            'results': results,\n",
    "            'inference_time': inference_time\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {img_num}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Initialize TensorRT model (run this once)\n",
    "print(\"Loading TensorRT engine...\")\n",
    "trt_model = TRTInference(\"test.engine\")\n",
    "print(\"TensorRT engine loaded successfully\")\n",
    "\n",
    "# Create a list of available image files\n",
    "image_files = [f for f in os.listdir(\"images\") if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "image_numbers = [f.split('.')[0] for f in image_files]\n",
    "print(f\"Available images: {image_numbers}\")\n",
    "\n",
    "# Create a dropdown for image selection\n",
    "image_dropdown = widgets.Dropdown(\n",
    "    options=image_numbers,\n",
    "    description='Image:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create a button to run inference\n",
    "run_button = widgets.Button(description='Run Inference')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        img_num = image_dropdown.value\n",
    "        print(f\"Running inference on image {img_num}\")\n",
    "        result = process_image(trt_model, img_num)\n",
    "        \n",
    "        if result:\n",
    "            # Display original and detection side by side\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            axes[0].imshow(result['original'])\n",
    "            axes[0].set_title('Original Image')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            axes[1].imshow(result['with_boxes'])\n",
    "            axes[1].set_title(f\"Detections ({len(result['results'])}) - {result['inference_time']:.2f}ms\")\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "run_button.on_click(on_button_click)\n",
    "\n",
    "# Display the UI components\n",
    "display(widgets.HBox([image_dropdown, run_button]))\n",
    "display(output_area)\n",
    "\n",
    "# For manual usage (alternative to the widgets)\n",
    "def run_detection(img_num):\n",
    "    result = process_image(trt_model, img_num)\n",
    "    \n",
    "    if result:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(result['original'])\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(result['with_boxes'])\n",
    "        plt.title(f\"Detections ({len(result['results'])}) - {result['inference_time']:.2f}ms\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Example usage: run_detection(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c0b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
